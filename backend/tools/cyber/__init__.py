"""
ðŸ›¡ï¸ GIDEON CYBER SECURITY TOOL â€” Defensive AI-SOC
=================================================

Azioni Avanzate (SOLO DIFENSIVE):
1. BehavioralBaselineBuilder - Costruisce baseline comportamentale
2. IncidentExplainabilityEngine - Traduce incidenti per umani
3. SupplyChainTrustScanner - Analizza dipendenze software
"""

from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
import hashlib
import json

@dataclass
class BehavioralBaseline:
    """Baseline comportamentale"""
    entity_type: str  # user, system, service
    entity_id: str
    normal_patterns: Dict[str, Any]
    anomaly_threshold: float
    last_updated: datetime
    confidence: float

@dataclass
class IncidentExplanation:
    """Spiegazione incidente"""
    incident_id: str
    technical_summary: str
    manager_summary: str
    operator_summary: str
    impact_assessment: str
    timeline: List[Dict[str, str]]
    root_cause: str
    confidence: float

@dataclass
class TrustScore:
    """Punteggio fiducia supply chain"""
    package_name: str
    version: str
    trust_score: float  # 0-100
    risks: List[str]
    recommendations: List[str]


class CyberTool:
    """
    ðŸ›¡ï¸ CYBER SECURITY TOOL - Defensive AI-SOC
    
    SOLO operazioni difensive.
    Nessuna capacitÃ  offensiva.
    """
    
    def __init__(self):
        self.baselines: Dict[str, BehavioralBaseline] = {}
        self.incidents: List[IncidentExplanation] = []
        self.trust_cache: Dict[str, TrustScore] = {}
    
    # ==================== ACTION 1: BehavioralBaselineBuilder ====================
    
    async def behavioral_baseline_builder(
        self,
        entity_type: str = "system",  # user, system, service
        entity_id: str = "default",
        learning_period_hours: int = 24,
        metrics: List[str] = None
    ) -> Dict[str, Any]:
        """
        ðŸ“Š BehavioralBaselineBuilder
        
        Costruisce baseline comportamentale per:
        - Utenti (pattern di accesso, azioni tipiche)
        - Sistemi (utilizzo risorse, pattern I/O)
        - Servizi (latenza, throughput, errori)
        
        Usato per rilevare deviazioni anomale.
        """
        
        metrics = metrics or self._get_default_metrics(entity_type)
        
        # Raccogli dati attuali (in produzione: storico reale)
        current_data = await self._collect_current_metrics(entity_type, metrics)
        
        # Calcola baseline statistica
        baseline = self._calculate_baseline(current_data, entity_type, entity_id)
        
        # Salva baseline
        self.baselines[f"{entity_type}:{entity_id}"] = baseline
        
        return {
            "success": True,
            "action": "behavioral_baseline_builder",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "entity": {
                    "type": entity_type,
                    "id": entity_id
                },
                "baseline": {
                    "metrics_tracked": metrics,
                    "normal_patterns": baseline.normal_patterns,
                    "anomaly_threshold": baseline.anomaly_threshold,
                    "learning_period": f"{learning_period_hours}h",
                    "samples_collected": current_data.get("sample_count", 100)
                },
                "detection_rules": self._generate_detection_rules(baseline),
                "status": "active"
            },
            "summary": f"Baseline per {entity_type}:{entity_id} costruita con successo",
            "recommendations": [
                "Monitorare deviazioni > 2Ïƒ dalla baseline",
                "Aggiornare baseline settimanalmente",
                "Escludere periodi di manutenzione programmata"
            ],
            "confidence": baseline.confidence
        }
    
    def _get_default_metrics(self, entity_type: str) -> List[str]:
        metrics_map = {
            "user": ["login_times", "session_duration", "actions_per_session", "locations"],
            "system": ["cpu_usage", "memory_usage", "disk_io", "network_io", "process_count"],
            "service": ["response_time", "error_rate", "throughput", "connections"]
        }
        return metrics_map.get(entity_type, ["generic_metric"])
    
    async def _collect_current_metrics(self, entity_type: str, metrics: List[str]) -> Dict[str, Any]:
        """Raccoglie metriche correnti"""
        import psutil
        
        data = {"sample_count": 100}  # Simulato
        
        if entity_type == "system":
            data["cpu_usage"] = {
                "mean": psutil.cpu_percent(),
                "std": 10.0,
                "min": 5.0,
                "max": 95.0
            }
            mem = psutil.virtual_memory()
            data["memory_usage"] = {
                "mean": mem.percent,
                "std": 8.0,
                "min": 40.0,
                "max": 95.0
            }
            data["process_count"] = {
                "mean": len(psutil.pids()),
                "std": 20,
                "min": 50,
                "max": 300
            }
        
        elif entity_type == "user":
            # Pattern utente simulato
            data["login_times"] = {
                "typical_hours": [8, 9, 10, 14, 15, 16],
                "weekend_activity": False
            }
            data["session_duration"] = {
                "mean": 45,  # minuti
                "std": 15
            }
        
        elif entity_type == "service":
            data["response_time"] = {
                "mean": 120,  # ms
                "std": 30,
                "p95": 200,
                "p99": 350
            }
            data["error_rate"] = {
                "mean": 0.5,  # %
                "std": 0.3
            }
        
        return data
    
    def _calculate_baseline(self, data: Dict, entity_type: str, entity_id: str) -> BehavioralBaseline:
        """Calcola baseline dai dati"""
        
        return BehavioralBaseline(
            entity_type=entity_type,
            entity_id=entity_id,
            normal_patterns=data,
            anomaly_threshold=2.0,  # 2 deviazioni standard
            last_updated=datetime.now(),
            confidence=0.85
        )
    
    def _generate_detection_rules(self, baseline: BehavioralBaseline) -> List[Dict[str, Any]]:
        """Genera regole di detection dalla baseline"""
        rules = []
        
        for metric, values in baseline.normal_patterns.items():
            if isinstance(values, dict) and "mean" in values and "std" in values:
                rules.append({
                    "metric": metric,
                    "condition": f"value > {values['mean'] + 2*values['std']:.2f} OR value < {values['mean'] - 2*values['std']:.2f}",
                    "severity": "medium",
                    "action": "alert"
                })
        
        return rules

    # ==================== ACTION 2: IncidentExplainabilityEngine ====================
    
    async def incident_explainability_engine(
        self,
        incident_data: Dict[str, Any] = None,
        target_audience: str = "all"  # technical, manager, operator, all
    ) -> Dict[str, Any]:
        """
        ðŸ“– IncidentExplainabilityEngine
        
        Traduce incidenti tecnici in:
        - Linguaggio tecnico (per SOC)
        - Linguaggio manageriale (per C-level)
        - Linguaggio operativo (per IT ops)
        
        Ogni spiegazione include impatto e raccomandazioni.
        """
        
        # Se non fornito, genera esempio
        incident_data = incident_data or self._generate_sample_incident()
        
        explanation = self._create_explanation(incident_data)
        
        response_data = {
            "incident_id": explanation.incident_id,
            "timestamp": datetime.now().isoformat(),
            "timeline": explanation.timeline,
            "root_cause": explanation.root_cause,
            "impact": explanation.impact_assessment,
            "confidence": f"{explanation.confidence:.0%}"
        }
        
        if target_audience in ["technical", "all"]:
            response_data["technical_explanation"] = {
                "summary": explanation.technical_summary,
                "details": incident_data.get("technical_details", {}),
                "iocs": incident_data.get("iocs", []),
                "affected_systems": incident_data.get("affected_systems", [])
            }
        
        if target_audience in ["manager", "all"]:
            response_data["manager_explanation"] = {
                "summary": explanation.manager_summary,
                "business_impact": self._calculate_business_impact(incident_data),
                "risk_level": incident_data.get("severity", "medium"),
                "estimated_cost": self._estimate_cost(incident_data)
            }
        
        if target_audience in ["operator", "all"]:
            response_data["operator_explanation"] = {
                "summary": explanation.operator_summary,
                "immediate_actions": self._get_immediate_actions(incident_data),
                "escalation_path": self._get_escalation_path(incident_data),
                "runbook_link": f"runbook://incident/{incident_data.get('type', 'generic')}"
            }
        
        return {
            "success": True,
            "action": "incident_explainability_engine",
            "timestamp": datetime.now().isoformat(),
            "data": response_data,
            "summary": f"Incidente {explanation.incident_id} analizzato - SeveritÃ : {incident_data.get('severity', 'medium').upper()}",
            "recommendations": self._get_recommendations(incident_data),
            "confidence": explanation.confidence
        }
    
    def _generate_sample_incident(self) -> Dict[str, Any]:
        """Genera incidente di esempio"""
        return {
            "id": f"INC-{datetime.now().strftime('%Y%m%d%H%M')}",
            "type": "unauthorized_access_attempt",
            "severity": "high",
            "detected_at": datetime.now().isoformat(),
            "source_ip": "192.168.1.100",
            "target": "auth-service",
            "technical_details": {
                "failed_attempts": 50,
                "time_window": "5 minutes",
                "pattern": "brute_force"
            },
            "affected_systems": ["auth-service", "user-database"],
            "iocs": ["192.168.1.100", "suspicious_user_agent"]
        }
    
    def _create_explanation(self, incident: Dict) -> IncidentExplanation:
        """Crea spiegazione multi-audience"""
        
        incident_type = incident.get("type", "unknown")
        
        explanations = {
            "unauthorized_access_attempt": {
                "technical": f"Rilevati {incident.get('technical_details', {}).get('failed_attempts', 'N')} tentativi di accesso falliti da {incident.get('source_ip', 'IP sconosciuto')} in {incident.get('technical_details', {}).get('time_window', 'N/A')}. Pattern identificato: {incident.get('technical_details', {}).get('pattern', 'unknown')}. IOC registrati per blocco.",
                "manager": "Ãˆ stato rilevato un tentativo di accesso non autorizzato ai nostri sistemi. L'attacco Ã¨ stato bloccato automaticamente. Nessun dato Ã¨ stato compromesso. Il team sta monitorando la situazione.",
                "operator": "âš ï¸ BRUTE FORCE DETECTED! IP bloccato automaticamente. Verifica che l'account target non sia compromesso. Controlla altri tentativi dallo stesso range IP."
            },
            "data_exfiltration": {
                "technical": "Rilevato traffico anomalo in uscita. Volume: oltre la baseline. Destinazione: IP non categorizzato. Protocollo: HTTPS con pattern sospetti.",
                "manager": "Ãˆ stato rilevato un potenziale tentativo di esfiltrazione dati. Il traffico Ã¨ stato interrotto. In corso analisi forense per determinare l'impatto.",
                "operator": "ðŸš¨ DATA EXFIL ALERT! Blocca immediatamente il traffico verso la destinazione indicata. Isola il sistema sorgente. Contatta il team IR."
            }
        }
        
        exp = explanations.get(incident_type, {
            "technical": f"Incidente di tipo {incident_type} rilevato.",
            "manager": "Rilevata anomalia di sicurezza. Team al lavoro.",
            "operator": "âš ï¸ Incidente rilevato. Segui runbook standard."
        })
        
        return IncidentExplanation(
            incident_id=incident.get("id", "INC-UNKNOWN"),
            technical_summary=exp["technical"],
            manager_summary=exp["manager"],
            operator_summary=exp["operator"],
            impact_assessment=self._assess_impact(incident),
            timeline=self._build_timeline(incident),
            root_cause=self._identify_root_cause(incident),
            confidence=0.82
        )
    
    def _assess_impact(self, incident: Dict) -> str:
        severity = incident.get("severity", "medium")
        affected = len(incident.get("affected_systems", []))
        
        if severity == "critical" or affected > 5:
            return "CRITICO - Potenziale impatto su operazioni business"
        elif severity == "high" or affected > 2:
            return "ALTO - Richiede attenzione immediata"
        elif severity == "medium":
            return "MEDIO - Da gestire entro 4 ore"
        return "BASSO - Gestione ordinaria"
    
    def _build_timeline(self, incident: Dict) -> List[Dict[str, str]]:
        detected = incident.get("detected_at", datetime.now().isoformat())
        return [
            {"time": detected, "event": "Incidente rilevato"},
            {"time": datetime.now().isoformat(), "event": "Analisi automatica completata"},
            {"time": "TBD", "event": "Mitigazione in corso"}
        ]
    
    def _identify_root_cause(self, incident: Dict) -> str:
        causes = {
            "unauthorized_access_attempt": "Tentativo di brute force da attore esterno",
            "data_exfiltration": "Possibile insider threat o malware",
            "malware_detected": "Infezione da vettore email/web",
            "ddos": "Attacco DDoS volumetrico"
        }
        return causes.get(incident.get("type", ""), "In fase di analisi")
    
    def _calculate_business_impact(self, incident: Dict) -> str:
        return f"Sistemi interessati: {len(incident.get('affected_systems', []))} - Utenti potenzialmente impattati: stimato 100-500"
    
    def _estimate_cost(self, incident: Dict) -> str:
        severity_cost = {"low": "< â‚¬1.000", "medium": "â‚¬1.000 - â‚¬10.000", "high": "â‚¬10.000 - â‚¬100.000", "critical": "> â‚¬100.000"}
        return severity_cost.get(incident.get("severity", "medium"), "Da valutare")
    
    def _get_immediate_actions(self, incident: Dict) -> List[str]:
        return [
            "1. Verificare contenimento automatico",
            "2. Raccogliere log per analisi",
            "3. Notificare stakeholder secondo matrice",
            "4. Documentare timeline"
        ]
    
    def _get_escalation_path(self, incident: Dict) -> List[str]:
        return ["L1 SOC Analyst", "L2 Security Engineer", "CISO (se critico)"]
    
    def _get_recommendations(self, incident: Dict) -> List[str]:
        return [
            "Bloccare IOC identificati su tutti i perimetri",
            "Verificare presence degli IOC negli ultimi 30 giorni",
            "Aggiornare regole SIEM con nuovi pattern",
            "Schedulare review post-incidente"
        ]

    # ==================== ACTION 3: SupplyChainTrustScanner ====================
    
    async def supply_chain_trust_scanner(
        self,
        packages: List[str] = None,
        scan_type: str = "quick"  # quick, deep
    ) -> Dict[str, Any]:
        """
        ðŸ”— SupplyChainTrustScanner
        
        Analizza dipendenze software:
        - VulnerabilitÃ  note (CVE)
        - Maintainer reputation
        - Update frequency
        - License compliance
        - Typosquatting detection
        
        Calcola rischio sistemico della supply chain.
        """
        
        # Se non forniti, analizza dipendenze comuni
        packages = packages or ["fastapi", "uvicorn", "pydantic", "requests", "numpy"]
        
        results = []
        total_risk = 0
        
        for pkg in packages:
            trust = await self._analyze_package(pkg, scan_type)
            results.append(trust)
            total_risk += (100 - trust.trust_score)
        
        avg_trust = 100 - (total_risk / len(packages))
        
        # Identifica rischi sistemici
        systemic_risks = self._identify_systemic_risks(results)
        
        return {
            "success": True,
            "action": "supply_chain_trust_scanner",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "scan_type": scan_type,
                "packages_analyzed": len(packages),
                "overall_trust_score": round(avg_trust, 1),
                "overall_risk_level": self._score_to_risk_level(avg_trust),
                "package_details": [
                    {
                        "name": t.package_name,
                        "version": t.version,
                        "trust_score": t.trust_score,
                        "risks": t.risks,
                        "recommendations": t.recommendations
                    }
                    for t in results
                ],
                "systemic_risks": systemic_risks,
                "dependency_tree_depth": "3 levels analyzed" if scan_type == "deep" else "1 level analyzed"
            },
            "summary": f"Supply chain trust score: {avg_trust:.0f}/100 - {len([r for r in results if r.trust_score < 70])} pacchetti richiedono attenzione",
            "recommendations": self._aggregate_supply_chain_recommendations(results),
            "confidence": 0.88
        }
    
    async def _analyze_package(self, package_name: str, scan_type: str) -> TrustScore:
        """Analizza singolo pacchetto"""
        
        # In produzione: query a database CVE, npm/pypi audit, etc.
        # Qui: simulazione realistica
        
        known_scores = {
            "fastapi": 95,
            "uvicorn": 92,
            "pydantic": 94,
            "requests": 88,
            "numpy": 96,
            "django": 93,
            "flask": 91,
            "express": 89,
            "lodash": 75,  # Ha avuto vulnerabilitÃ  storiche
            "log4j": 30,   # Esempio critico
        }
        
        base_score = known_scores.get(package_name, 80)
        
        # Simula variazione
        import random
        score = min(100, max(0, base_score + random.randint(-5, 5)))
        
        risks = []
        recommendations = []
        
        if score < 70:
            risks.append("VulnerabilitÃ  note non patchate")
            recommendations.append("Aggiornare alla versione piÃ¹ recente")
        if score < 80:
            risks.append("Maintainer con attivitÃ  ridotta")
            recommendations.append("Valutare alternative attivamente mantenute")
        if score < 90:
            risks.append("Dipendenze transitive con rischi")
            recommendations.append("Audit dipendenze con 'pip audit' o 'npm audit'")
        
        if not risks:
            risks = ["Nessun rischio significativo rilevato"]
            recommendations = ["Mantenere aggiornato"]
        
        return TrustScore(
            package_name=package_name,
            version="latest",
            trust_score=score,
            risks=risks,
            recommendations=recommendations
        )
    
    def _identify_systemic_risks(self, results: List[TrustScore]) -> List[str]:
        """Identifica rischi sistemici"""
        risks = []
        
        low_trust = [r for r in results if r.trust_score < 70]
        if low_trust:
            risks.append(f"{len(low_trust)} pacchetti con trust score critico")
        
        # Check per dipendenze comuni vulnerabili
        critical_pkgs = ["log4j", "lodash", "event-stream"]
        found_critical = [r.package_name for r in results if r.package_name in critical_pkgs]
        if found_critical:
            risks.append(f"Dipendenze critiche trovate: {', '.join(found_critical)}")
        
        if not risks:
            risks = ["Nessun rischio sistemico identificato"]
        
        return risks
    
    def _score_to_risk_level(self, score: float) -> str:
        if score >= 90:
            return "LOW"
        elif score >= 75:
            return "MEDIUM"
        elif score >= 50:
            return "HIGH"
        return "CRITICAL"
    
    def _aggregate_supply_chain_recommendations(self, results: List[TrustScore]) -> List[str]:
        all_recs = []
        for r in results:
            all_recs.extend(r.recommendations)
        
        # Deduplica e limita
        unique_recs = list(set(all_recs))[:5]
        
        # Aggiungi best practices generali
        unique_recs.extend([
            "Implementare Software Bill of Materials (SBOM)",
            "Configurare Dependabot o Renovate per aggiornamenti automatici"
        ])
        
        return unique_recs[:7]


# Singleton instance
_cyber_tool = None

def get_cyber_tool() -> CyberTool:
    global _cyber_tool
    if _cyber_tool is None:
        _cyber_tool = CyberTool()
    return _cyber_tool
